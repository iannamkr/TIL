(on writing...)

## 1. Query execution

> 3 layers: 
> logical planning -> physical planning -> execution

### Logical planning 
- logical plan created, analyzed, optimized
- tree representation of query
- abstraction of information about what is supposed to happen
- not contain precise information on how it happens
- composed of
  - relational operators 
    - filter, join, procest ( dataframe transformations )
  - expressions
    - column transformations, filtering conditions, joining conditions
    
## 2. Physical planning
- optimized logical plan
- not understand dataframe / logical plan (LP)
- logical plan has to be converted to a physical plan (PP)
- physical plan
  - bridge between LP and RDDs
  - similarly to logical plan it is a tree
  - contains more specific description of how thins should happen (specific choice of alghorithms)
  - uses lower level primitives - RDDs
  
#### planning - 2 phases

spark plan -> _additional rules_ -> executed plan

- spark plan
  - generated by query planner using strategies
  - for each node in lp
    - e.g) `Join`
  
  - there is a node in pp
    - e.g) `SortMergeJoin`, `BroadcastHashJoin`

- _additional rules_
  - strategy example: Join Selection
  

- executed plan
  - Final version of query plan
  - this will be executed
    - generates RDD code
    ```scala
    df.explain()
    df.queryExecution.sparkPlan
    df.queryExecution.executedPlan
    ```
    
## 3. Spark ui

![image](https://user-images.githubusercontent.com/13671946/79093388-1edfcc00-7d8f-11ea-867f-1b59b1e2aa42.png)

- FileScan: Represents reading the data from a file format
```scala
spark.table("posts_fb")
.filter($"month" === 5)
.filter($"profile_id" === ...)
```
- table: `posts_fb`
- partitioned by `month`
- bucketed by `profile_id`
- 1 file per bucket

<img width="315" alt="스크린샷 2020-04-16 오후 2 49 02" src="https://user-images.githubusercontent.com/13671946/79419264-75e4db80-7ff1-11ea-8632-aec0f73645fb.png">

- number of files read
<img width="709" alt="스크린샷 2020-04-16 오후 2 52 39" src="https://user-images.githubusercontent.com/13671946/79419533-f0adf680-7ff1-11ea-996c-503d0b8fcc38.png">


> bucket pruning 이란?
- partition pruning과 개념은 유사하나 더 작은 단위인 bucket으로 pruning을 수행하는 것이다. 
- bucket은 "partition inside a partition" 으로 partiiton을 특정 컬럼들의 hash value를 통해 나눈 것이다. cardinality가 높은 column의 경우 bucket pruning을 통해 불필요한 데이터의 액세스 방지로 성능상의 이점을 가질 수 있다.
  


## ref
- Physical Plans in Spark SQL - David Vrba (Socialbakers): https://www.youtube.com/watch?time_continue=1491&v=99fYi2mopbs&feature=emb_logo
